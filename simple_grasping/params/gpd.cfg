# Path to config file for robot hand geometry
hand_geometry_filename = 0

# Path to config file for volume and image geometry
image_geometry_filename = 0

# ==== Robot Hand Geometry ====
#   finger_width: the width of the finger
#   outer_diameter: the diameter of the robot hand (= maximum aperture + 2 * finger width)
#   hand_depth: the finger length (measured from hand base to finger tip)
#   hand_height: the height of the hand
#   init_bite: the minimum amount of the object to be covered by the hand
finger_width = 0.01
hand_outer_diameter = 0.12
hand_depth = 0.06
hand_height = 0.02
init_bite = 0.01

# ==== Grasp Descriptor ====
#   volume_width: the width of the cube inside the robot hand
#   volume_depth: the depth of the cube inside the robot hand
#   volume_height: the height of the cube inside the robot hand
#   image_size: the size of the image (width and height; image is square)
#   image_num_channels: the number of image channels
volume_width = 0.10
volume_depth = 0.06
volume_height = 0.02
image_size = 60
image_num_channels = 15

# (OpenVINO) Path to directory that contains neural network parameters
weights_file = /opt/gpd/models/lenet/15channels/params/

# Preprocessing of point cloud
#   voxelize: if the cloud gets voxelized/downsampled
#   remove_outliers: if statistical outliers are removed from the cloud (used to remove noise)
#   workspace: the workspace of the robot (dimensions of a cube centered at origin of point cloud)
#   camera_position: the position of the camera from which the cloud was taken
#   sample_above_plane: only draws samples which do not belong to the table plane
voxelize = 0
voxel_size = 0.003
remove_outliers = 0
workspace = -0.5 0.5 -0.5 10.5 -0.5 0.5
camera_position = 0 0 0
sample_above_plane = 0

# Grasp candidate generation
#   num_samples: number of samples to be drawn from the point cloud
#   num_threads: number of CPU threads to be used
#   nn_radius: neighborhood search radius for the local reference frame estimation
#   num_orientations: number of robot hand orientations to evaluate
#   num_finger_placements: number of finger placements to evaluate
#   hand_axes: axes about which the point neighborhood gets rotated (0: approach, 1: binormal, 2: axis)
#              (see https://raw.githubusercontent.com/atenpas/gpd2/master/readme/hand_frame.png)
#   deepen_hand: if the hand is pushed forward onto the object
#   friction_coeff: angle of friction cone in degrees
#   min_viable: minimum number of points required on each side to be antipodal
num_samples = 200
num_threads = 8
nn_radius = 0.05
num_orientations = 10
num_finger_placements = 20
hand_axes = 2
deepen_hand = 1
friction_coeff = 1
min_viable = 5


# Filtering of candidates
#   min_aperture: the minimum gripper width
#   max_aperture: the maximum gripper width
#   workspace_grasps: dimensions of a cube centered at origin of point cloud; should be smaller than <workspace>
min_aperture = 0.0
max_aperture = 0.85
workspace_grasps = -0.5 0.5 -0.5 0.5 -0.5 0.5

# Clustering of grasps
#   min_inliers: minimum number of inliers per cluster; set to 0 to turn off clustering
min_inliers = 1